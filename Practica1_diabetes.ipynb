{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbOTJpwGXsqa"
      },
      "source": [
        "# üìù **Pr√°ctica #1:** üöÄ Construcci√≥n de una red neuronal para la predicci√≥n de diabetes\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LoboaTeresa/Workshop-COF-23/blob/main/Practica1_diabetes.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5REUUbURYSvi"
      },
      "source": [
        "### 1. Cargar el dataset: Pima Indians Diabetes Database\n",
        "\n",
        "Este dataset procede del Instituto Nacional de Diabetes y Enfermedades Digestivas y Renales de EEUU. El objetivo de este dataset es diagnosticar si un paciente es diab√©tico o no, bas√°ndose en 8 par√°metros.\n",
        "\n",
        "* 1990\n",
        "* Dataset de clasificaci√≥n binaria\n",
        "* 8 par√°metros reales y enteros\n",
        "* 768 instancias\n",
        "* 100% de os pacientes son mujeres, de la etnia india Pima y > 21 a√±os de edad.\n",
        "\n",
        "Par√°metros:\n",
        "1. Embarazos\n",
        "2. Glocosa\n",
        "3. Presi√≥n Arterial\n",
        "4. Espesor de la piel\t\n",
        "5. Insulina\n",
        "6. IMC\n",
        "7. DiabetesPedigreeFunction\n",
        "8. Edad\n",
        "9. Diagn√≥sitco (1: diab√©tico, 0: no diab√©tico)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# descarga el dataset:\n",
        "!git clone https://github.com/LoboaTeresa/Workshop-COF-23.git\n",
        "!cp /content/Workshop-COF-23/assets/pima-indians-diabetes.csv /content/pima-indians-diabetes.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "seed = 7 # para la reproducibilidad del experimento\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar el dataset de los indios Pima.\n",
        "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# Dividir los datos en par√°metros y label (o verdad).\n",
        "X = dataset[:, 0:8]\n",
        "Y = dataset[:, 8]\n",
        "\n",
        "# Dividir los datos en entrenamiento y test.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
        "                                                    test_size=0.20, \n",
        "                                                    random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-160j4hYzvB"
      },
      "source": [
        "### 2. Definici√≥n de la arquitectura:\n",
        "\n",
        "[Documentaci√≥n de Keras](https://keras.io/api/layers/). √âchale un ojo :)\n",
        "\n",
        "Vamos a construir una red neuronal de 4 capas densas o completamente conectadas.\n",
        "\n",
        "![Simple Network](https://github.com/LoboaTeresa/Workshop-COF-23/blob/main/assets/simple_net.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializamos el modelo de Keras\n",
        "model = Sequential()\n",
        "\n",
        "model.add(_INSERT_LAYER_HERE_(?, input_shape=?, activation='relu'))\n",
        "model.add(_INSERT_LAYER_HERE_(?, activation='relu'))\n",
        "model.add(_INSERT_LAYER_HERE_(?, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUvfz1y-ZTEC"
      },
      "source": [
        "### 3. Compilar el modelo\n",
        "\n",
        "Una vez que el modelo esta definido, se procede a compilarlo. Al compilar el modelo, se llama a las librerias en el backend, en nuestro caso Tensorflow. En este caso el backend autom√°ticamente selecciona la mejor forma de representar la red neuronal para entrenamiento y realizar predicciones en el hardware. Cuando se compila el modelo, se deben definir algunas propiedades adicionales requeridas para el entrenamiento del modelo:\n",
        "\n",
        "* **Funci√≥n de p√©rdida** o loss function, que es utilizada para evaluar los pesos.\n",
        "* **Optimizador** utilizado para buscar entre los pesos de la red y algunas m√©tricas opcionales que se require colectar y reportar durante el entrenamiento.\n",
        "\n",
        "En este ejemplo utilizaremos una funci√≥n de perdida **binary cross entropy**, que es una funci√≥n logar√≠tmica de perdida. Se utilizar√° una funci√≥n para los calcular los gradientes llamada **adam**.\n",
        "\n",
        "Al ser un problema de clasificaci√≥n binaria, se evaluar√° la precision de la clasificaci√≥n utilizando accuracy (n√∫mero de predicciones correctas/n√∫mero de datos totales).\n",
        "\n",
        "_M√°s info sobre binary cross entropy [aqu√≠](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a)._\n",
        "\n",
        "_M√°s info sobre el optimizador Adam [aqu√≠](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuD9Pc0_ZjR7"
      },
      "source": [
        "### 4. Entrenar el modelo\n",
        "\n",
        "Una vez que este definido y compilado tu modelo, es el momento de ejecutar el modelo con los datos.\n",
        "\n",
        "El proceso de entrenamiento se ejecuta cierto numero de veces utilizando el dataset, este numero de veces es llamado epochs, y se define utilizando el par√°metro _epochs_. Tambi√©n podemos definir el numero de instancias que son evaluadas antes de que los pesos sean actualizados en la red neuronal. Este par√°metro se llama _batch size_.\n",
        "\n",
        "En este problema se definir√° un numero peque√±o de epochs (150) y un valor relativamente peque√±o de el batch (10)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, Y_train, epochs=150, batch_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgrALvMlaWBT"
      },
      "source": [
        "### 5. Eval√∫a tu modelo\n",
        "\n",
        "Ahora que hemos entrenado nuestro modelo utilizando el dataset completo, debemos evaluar el rendimiento de la red neuronal. Estos nos data una idea que tan bien modelamos nuestro dataset, pero no tendremos idea como se desempe√±ara el modelo con datos nuevos.\n",
        "\n",
        "En la realidad se debe de separar el dataset de training y el dataset de testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqtLHFfSkJEm",
        "outputId": "a1b8ddbb-2f90-4ab4-d2d5-f3c04f810c6c"
      },
      "outputs": [],
      "source": [
        "_, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Matriz de confusi√≥n:** es una herramienta que permite visualizar el desempe√±o de un algoritmo  de aprendizaje supervisado. Cada columna de la matriz representa el n√∫mero de predicciones de cada clase, mientras que cada fila representa a las instancias en la clase real., o sea en t√©rminos pr√°cticos nos permite ver  qu√© tipos de aciertos y errores est√° teniendo nuestro modelo a la hora de pasar por el proceso de aprendizaje con los datos.\n",
        "\n",
        "<img src=\"https://github.com/LoboaTeresa/Workshop-COF-23/blob/main/assets/CM_explained.png?raw=true\"\n",
        "     alt=\"confusionMatrix\"\n",
        "     width=400 />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn.metrics as metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "predictions = (model.predict(X_test) > 0.5).astype(int)\n",
        "cm = metrics.confusion_matrix(Y_test, predictions)\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])\n",
        "cm_display.plot()\n",
        "plt.figure(figsize=(50, 50), dpi=80)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjkCqodNajko"
      },
      "source": [
        "### 6. Realiza una predicci√≥n (inferencia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3HFAW3Nam6W",
        "outputId": "b40fb2db-1444-4ef2-8e3e-3624181e1648"
      },
      "outputs": [],
      "source": [
        "# summarize the first 5 cases\n",
        "for i in range(5):\n",
        " print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], Y[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgdbL3UQaeQy"
      },
      "source": [
        "**¬°BUEN TRABAJO!** Ahora que hemos entrenado nuestro modelo, podemos utilizarlo para realizar predicciones sobre datos nuevos.\n",
        "\n",
        "### 7. Conclusi√≥n\n",
        "\n",
        "Hemos seguido los siguientes pasos:\n",
        "\n",
        "* Cargar datos.\n",
        "* Definir el modelo de la red neuronal en Keras.\n",
        "* Compilar el modelo.\n",
        "* Entrenar el modelo.\n",
        "* Evaluar el modelo con datos"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
